{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and functions.\n",
    ".\n",
    "\n",
    "</p>Search for archives, and create the 1st data frame, as well as an empty list for the headers (h) and the list for comun columns (CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pyspark.sql.functions import concat, col, lit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Using the <code>glob</code> library allows us to create a list with only the csv that are ended in <em>(Normalized).csv</em> , which will be the most useful for a statistical analysis. <br>\n",
    "Moreover, for a future simplification, we also create a list with the relevant information of each of the csv <em>('Area','Year','Element','Unit','Value')</em> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(os.getcwd()+ \"/Data/\"+\"/**(Normalized).csv\")\n",
    "CC=['Area','Year','Element' or 'Item','Unit','Value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intitiate the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "  \n",
    "ss = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Our First Spark example\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Header locator, to know which are the variables in each csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Element\n",
      "['Area Code', 'Area', 'Item Code', 'Item', 'Months Code', 'Months', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Note']\n",
      "5\n",
      "Area\n",
      "['Donor Code', 'Donor', 'Recipient Country Code', 'Recipient Country', 'Item Code', 'Item', 'Element Code', 'Element', 'Purpose Code', 'Purpose', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Note']\n",
      "20\n",
      "Element\n",
      "['Area Code', 'Area', 'Source Code', 'Source', 'Indicator Code', 'Indicator', 'Sex Code', 'Sex', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Note']\n",
      "20\n",
      "Item\n",
      "['Area Code', 'Area', 'Source Code', 'Source', 'Indicator Code', 'Indicator', 'Sex Code', 'Sex', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Note']\n",
      "21\n",
      "Element\n",
      "['Area Code', 'Area', 'Source Code', 'Source', 'Indicator Code', 'Indicator', 'Sex Code', 'Sex', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Note']\n",
      "21\n",
      "Item\n",
      "['Area Code', 'Area', 'Source Code', 'Source', 'Indicator Code', 'Indicator', 'Sex Code', 'Sex', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Note']\n",
      "22\n",
      "Element\n",
      "['Area Code', 'Area', 'Source Code', 'Source', 'Indicator Code', 'Indicator', 'Sex Code', 'Sex', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Note']\n",
      "22\n",
      "Item\n",
      "['Area Code', 'Area', 'Source Code', 'Source', 'Indicator Code', 'Indicator', 'Sex Code', 'Sex', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Note']\n",
      "32\n",
      "Item\n",
      "['Area Code', 'Area', 'Months Code', 'Months', 'Element Code', 'Element', 'Year Code', 'Year', 'Unit', 'Value', 'Flag']\n",
      "34\n",
      "Element\n",
      "['Area Code', 'Area', 'Item Code', 'Item', 'ISO Currency Code', 'Currency', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Note']\n",
      "37\n",
      "Area\n",
      "['Recipient Country Code', 'Recipient Country', 'Item Code', 'Item', 'Element Code', 'Element', 'Year Code', 'Year', 'Unit', 'Value', 'Flag', 'Note']\n",
      "40\n",
      "Area\n",
      "['Reporter Country Code (FAO)', 'Reporter Country Code (M49)', 'Reporter Countries', 'Partner Country Code (FAO)', 'Partner Country Code (M49)', 'Partner Countries', 'Item Code (FAO)', 'Item', 'Element Code (FAO)', 'Element', 'Year Code (FAO)', 'Year', 'Unit', 'Value', 'Flag']\n",
      "41\n",
      "Element\n",
      "['Survey Code', 'Survey', 'Breakdown Variable Code', 'Breakdown Variable', 'Breadown by Sex of the Household Head Code', 'Breadown by Sex of the Household Head', 'Indicator Code', 'Indicator', 'Measure Code', 'Measure', 'Unit', 'Value', 'Flag']\n",
      "41\n",
      "Item\n",
      "['Survey Code', 'Survey', 'Breakdown Variable Code', 'Breakdown Variable', 'Breadown by Sex of the Household Head Code', 'Breadown by Sex of the Household Head', 'Indicator Code', 'Indicator', 'Measure Code', 'Measure', 'Unit', 'Value', 'Flag']\n",
      "41\n",
      "Area\n",
      "['Survey Code', 'Survey', 'Breakdown Variable Code', 'Breakdown Variable', 'Breadown by Sex of the Household Head Code', 'Breadown by Sex of the Household Head', 'Indicator Code', 'Indicator', 'Measure Code', 'Measure', 'Unit', 'Value', 'Flag']\n",
      "41\n",
      "Year\n",
      "['Survey Code', 'Survey', 'Breakdown Variable Code', 'Breakdown Variable', 'Breadown by Sex of the Household Head Code', 'Breadown by Sex of the Household Head', 'Indicator Code', 'Indicator', 'Measure Code', 'Measure', 'Unit', 'Value', 'Flag']\n",
      "64\n",
      "Area\n",
      "['Reporter Country Code', 'Reporter Countries', 'Partner Country Code', 'Partner Countries', 'Item Code', 'Item', 'Element Code', 'Element', 'Year Code', 'Year', 'Unit', 'Value', 'Flag']\n",
      "67\n",
      "Year\n",
      "['Area Code', 'Area', 'Item Code', 'Item', 'Element Code', 'Element', 'WCA Round code', 'WCA Round', 'Census Year Code', 'Census Year', 'Unit', 'Value', 'Flag', 'Note']\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,len(file_list)):\n",
    "    file1=ss.read.csv(file_list[i], header=True)\n",
    "    if 'Element' in file1.schema.fieldNames():\n",
    "        if 'Item' in file1.schema.fieldNames():\n",
    "            if 'Area' in file1.schema.fieldNames():\n",
    "                if 'Year' in file1.schema.fieldNames():\n",
    "                    if 'Unit' in file1.schema.fieldNames():\n",
    "                        if 'Value' in file1.schema.fieldNames():\n",
    "                            pass\n",
    "                        else:\n",
    "                            print(i)\n",
    "                            print('Value')\n",
    "                            print(file1.schema.fieldNames())\n",
    "                    else:\n",
    "                        print(i)\n",
    "                        print('Unit')\n",
    "                        print(file1.schema.fieldNames())    \n",
    "                else:\n",
    "                    print(i)\n",
    "                    print('Year')\n",
    "                    print(file1.schema.fieldNames())\n",
    "            else:\n",
    "                print(i)\n",
    "                print('Area')\n",
    "                print(file1.schema.fieldNames())\n",
    "        else:\n",
    "            print(i)\n",
    "            print('Item')\n",
    "            print(file1.schema.fieldNames())\n",
    "    else:\n",
    "        print(i) \n",
    "        print('Element')\n",
    "        print(file1.schema.fieldNames())\n",
    "        if 'Item' in file1.schema.fieldNames():\n",
    "            if 'Area' in file1.schema.fieldNames():\n",
    "                if 'Year' in file1.schema.fieldNames():\n",
    "                    if 'Unit' in file1.schema.fieldNames():\n",
    "                        if 'Value' in file1.schema.fieldNames():\n",
    "                            pass\n",
    "                        else:\n",
    "                            print(i)\n",
    "                            print('Value')\n",
    "                            print(file1.schema.fieldNames())\n",
    "                    else:\n",
    "                        print(i)\n",
    "                        print('Unit')\n",
    "                        print(file1.schema.fieldNames())    \n",
    "                else:\n",
    "                    print(i)\n",
    "                    print('Year')\n",
    "                    print(file1.schema.fieldNames())\n",
    "            else:\n",
    "                print(i)\n",
    "                print('Area')\n",
    "                print(file1.schema.fieldNames())\n",
    "        else:\n",
    "            print(i)\n",
    "            print('Item')\n",
    "            print(file1.schema.fieldNames())\n",
    "            if 'Area' in file1.schema.fieldNames():\n",
    "                if 'Year' in file1.schema.fieldNames():\n",
    "                    if 'Unit' in file1.schema.fieldNames():\n",
    "                        if 'Value' in file1.schema.fieldNames():\n",
    "                            pass\n",
    "                        else:\n",
    "                            print(i)\n",
    "                            print('Value')\n",
    "                            print(file1.schema.fieldNames())\n",
    "                    else:\n",
    "                        print(i)\n",
    "                        print('Unit')\n",
    "                        print(file1.schema.fieldNames())    \n",
    "                else:\n",
    "                    print(i)\n",
    "                    print('Year')\n",
    "                    print(file1.schema.fieldNames())\n",
    "            else:\n",
    "                print(i)\n",
    "                print('Area')\n",
    "                print(file1.schema.fieldNames())\n",
    "                if 'Year' in file1.schema.fieldNames():\n",
    "                    if 'Unit' in file1.schema.fieldNames():\n",
    "                        if 'Value' in file1.schema.fieldNames():\n",
    "                            pass\n",
    "                        else:\n",
    "                            print(i)\n",
    "                            print('Value')\n",
    "                            print(file1.schema.fieldNames())\n",
    "                    else:\n",
    "                        print(i)\n",
    "                        print('Unit')\n",
    "                        print(file1.schema.fieldNames())    \n",
    "                else:\n",
    "                    print(i)\n",
    "                    print('Year')\n",
    "                    print(file1.schema.fieldNames())\n",
    "                    if 'Unit' in file1.schema.fieldNames():\n",
    "                        if 'Value' in file1.schema.fieldNames():\n",
    "                            pass\n",
    "                        else:\n",
    "                            print(i)\n",
    "                            print('Value')\n",
    "                            print(file1.schema.fieldNames())\n",
    "                    else:\n",
    "                        print(i)\n",
    "                        print('Unit')\n",
    "                        print(file1.schema.fieldNames())\n",
    "                        if 'Value' in file1.schema.fieldNames():\n",
    "                            pass\n",
    "                        else:\n",
    "                            print(i)\n",
    "                            print('Value')\n",
    "                            print(file1.schema.fieldNames())\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will allow to read  the csv files from the main directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+--------------------------------------------------------------------------------------------+---------+\n",
      "|Area               |Year|Unique                                                                                      |Value    |\n",
      "+-------------------+----+--------------------------------------------------------------------------------------------+---------+\n",
      "|Algeria            |2009|Agriculture research spending - Share of Value Added (Agriculture, Forestry and Fishing) - %|0.180000 |\n",
      "|Algeria            |2010|Agriculture research spending - Share of Value Added (Agriculture, Forestry and Fishing) - %|0.180000 |\n",
      "|Algeria            |2011|Agriculture research spending - Share of Value Added (Agriculture, Forestry and Fishing) - %|0.210000 |\n",
      "|Algeria            |2012|Agriculture research spending - Share of Value Added (Agriculture, Forestry and Fishing) - %|0.210000 |\n",
      "|Algeria            |2009|Agriculture research spending - Spending, total - million PPP (constant 2011 prices)        |76.900000|\n",
      "|Algeria            |2010|Agriculture research spending - Spending, total - million PPP (constant 2011 prices)        |71.000000|\n",
      "|Algeria            |2011|Agriculture research spending - Spending, total - million PPP (constant 2011 prices)        |82.900000|\n",
      "|Algeria            |2012|Agriculture research spending - Spending, total - million PPP (constant 2011 prices)        |91.600000|\n",
      "|Antigua and Barbuda|2007|Agriculture research spending - Share of Value Added (Agriculture, Forestry and Fishing) - %|4.200000 |\n",
      "|Antigua and Barbuda|2008|Agriculture research spending - Share of Value Added (Agriculture, Forestry and Fishing) - %|3.810000 |\n",
      "|Antigua and Barbuda|2009|Agriculture research spending - Share of Value Added (Agriculture, Forestry and Fishing) - %|4.020000 |\n",
      "|Antigua and Barbuda|2010|Agriculture research spending - Share of Value Added (Agriculture, Forestry and Fishing) - %|3.680000 |\n",
      "|Antigua and Barbuda|2011|Agriculture research spending - Share of Value Added (Agriculture, Forestry and Fishing) - %|3.650000 |\n",
      "|Antigua and Barbuda|2012|Agriculture research spending - Share of Value Added (Agriculture, Forestry and Fishing) - %|2.980000 |\n",
      "|Antigua and Barbuda|2007|Agriculture research spending - Spending, total - million PPP (constant 2011 prices)        |1.500000 |\n",
      "|Antigua and Barbuda|2008|Agriculture research spending - Spending, total - million PPP (constant 2011 prices)        |1.300000 |\n",
      "|Antigua and Barbuda|2009|Agriculture research spending - Spending, total - million PPP (constant 2011 prices)        |1.200000 |\n",
      "|Antigua and Barbuda|2010|Agriculture research spending - Spending, total - million PPP (constant 2011 prices)        |1.100000 |\n",
      "|Antigua and Barbuda|2011|Agriculture research spending - Spending, total - million PPP (constant 2011 prices)        |1.300000 |\n",
      "|Antigua and Barbuda|2012|Agriculture research spending - Spending, total - million PPP (constant 2011 prices)        |1.000000 |\n",
      "+-------------------+----+--------------------------------------------------------------------------------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file0 = ss.read.csv(file_list[0], sep=',',header= True)\n",
    "file0=file0.select('Area','Year', (concat(col('Item'),lit(' - '), col('Element'),lit(' - '),col('Unit'))).alias('Unique'),'Value')\n",
    "file0.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop attempt; not everyone has element or item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'Element' given input columns: [Area, Area Code, Flag, Item, Item Code, Months, Months Code, Note, Unit, Value, Year, Year Code];\n'Project [Area#33975, Year#33981, concat(Item#33977,  - , 'Element,  - , Unit#33982) AS Unique#33998, Value#33983]\n+- Relation [Area Code#33974,Area#33975,Item Code#33976,Item#33977,Months Code#33978,Months#33979,Year Code#33980,Year#33981,Unit#33982,Value#33983,Flag#33984,Note#33985] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\amarchve\\Documents\\GitHub\\python-data-driven-decisions\\Data-integration.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/amarchve/Documents/GitHub/python-data-driven-decisions/Data-integration.ipynb#ch0000014?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (\u001b[39m1\u001b[39m,\u001b[39mlen\u001b[39m(file_list)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/amarchve/Documents/GitHub/python-data-driven-decisions/Data-integration.ipynb#ch0000014?line=1'>2</a>\u001b[0m     file1\u001b[39m=\u001b[39mss\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39mcsv(file_list[i], header\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/amarchve/Documents/GitHub/python-data-driven-decisions/Data-integration.ipynb#ch0000014?line=2'>3</a>\u001b[0m     file1\u001b[39m=\u001b[39mfile1\u001b[39m.\u001b[39;49mselect(\u001b[39m'\u001b[39;49m\u001b[39mArea\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mYear\u001b[39;49m\u001b[39m'\u001b[39;49m, (concat(col(\u001b[39m'\u001b[39;49m\u001b[39mItem\u001b[39;49m\u001b[39m'\u001b[39;49m),lit(\u001b[39m'\u001b[39;49m\u001b[39m - \u001b[39;49m\u001b[39m'\u001b[39;49m), col(\u001b[39m'\u001b[39;49m\u001b[39mElement\u001b[39;49m\u001b[39m'\u001b[39;49m),lit(\u001b[39m'\u001b[39;49m\u001b[39m - \u001b[39;49m\u001b[39m'\u001b[39;49m),col(\u001b[39m'\u001b[39;49m\u001b[39mUnit\u001b[39;49m\u001b[39m'\u001b[39;49m)))\u001b[39m.\u001b[39;49malias(\u001b[39m'\u001b[39;49m\u001b[39mUnique\u001b[39;49m\u001b[39m'\u001b[39;49m),\u001b[39m'\u001b[39;49m\u001b[39mValue\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/amarchve/Documents/GitHub/python-data-driven-decisions/Data-integration.ipynb#ch0000014?line=3'>4</a>\u001b[0m     file0\u001b[39m=\u001b[39mfile0\u001b[39m.\u001b[39munion(file1)\n",
      "File \u001b[1;32mc:\\Users\\amarchve\\Documents\\GitHub\\python-data-driven-decisions\\.venv\\lib\\site-packages\\pyspark\\sql\\dataframe.py:1685\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m   1664\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcols):\n\u001b[0;32m   1665\u001b[0m     \u001b[39m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m \n\u001b[0;32m   1667\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1683\u001b[0m \u001b[39m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[0;32m   1684\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1685\u001b[0m     jdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mselect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jcols(\u001b[39m*\u001b[39;49mcols))\n\u001b[0;32m   1686\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(jdf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msql_ctx)\n",
      "File \u001b[1;32mc:\\Users\\amarchve\\Documents\\GitHub\\python-data-driven-decisions\\.venv\\lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[1;32mc:\\Users\\amarchve\\Documents\\GitHub\\python-data-driven-decisions\\.venv\\lib\\site-packages\\pyspark\\sql\\utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    113\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[0;32m    114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    115\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: cannot resolve 'Element' given input columns: [Area, Area Code, Flag, Item, Item Code, Months, Months Code, Note, Unit, Value, Year, Year Code];\n'Project [Area#33975, Year#33981, concat(Item#33977,  - , 'Element,  - , Unit#33982) AS Unique#33998, Value#33983]\n+- Relation [Area Code#33974,Area#33975,Item Code#33976,Item#33977,Months Code#33978,Months#33979,Year Code#33980,Year#33981,Unit#33982,Value#33983,Flag#33984,Note#33985] csv\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,len(file_list)):\n",
    "    file1=ss.read.csv(file_list[i], header=True)\n",
    "    file1=file1.select('Area','Year', (concat(col('Item'),lit(' - '), col('Element'),lit(' - '),col('Unit'))).alias('Unique'),'Value')\n",
    "    file0=file0.union(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Loop attempt2; looks promising, not finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1332274217.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [12]\u001b[1;36m\u001b[0m\n\u001b[1;33m    if i == #put number where the damm archive is:\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,len(file_list)):\n",
    "    if i == # put number where the damm archive is:\n",
    "        continue\n",
    "    else:\n",
    "        file1=ss.read.csv(file_list[i], header=True)\n",
    "        if 'Element' in file1.schema.fieldNames():\n",
    "            if 'Item' in file1.schema.fieldNames():\n",
    "                if 'Area' in file1.schema.fieldNames():\n",
    "                    pass \n",
    "                else:\n",
    "                    file1=file1.withColumn('Area',col('Recipient Country'))\n",
    "            else:\n",
    "                file1=file1.withColumn('Item', lit(0))\n",
    "        else:\n",
    "            file1=file1.withColumn('Element', lit(0))\n",
    "            if 'Item' in file1.schema.fieldNames():\n",
    "                pass\n",
    "            else:\n",
    "                file1=file1.withColumn('Item', lit(0))\n",
    "        file1=file1.select('Area' or 'Country','Year', (concat(col('Item'),lit(' - '), col('Element'),lit(' - '),col('Unit'))).alias('Unique'),'Value')\n",
    "        file0=file0.union(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Area Code', 'Item Code', 'Element Code', 'Year Code', 'Source Code']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1=ss.read.csv(file_list[18], header=True)\n",
    "[element for element in file1.columns if 'Cod' in element]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data integration through pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As at the beginning we do not have enough computer power to process the whole database, we are going to develop a test run to be sure that the ideas are escalable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first test run for the loop, we are going to load and process the data into concated data frames, where later on, there is an application of the <code>pivot_table</code> function which adjusts all the variables, previouly called 'Elements' & 'Units' into the headers of the columns, and the values the values of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataframe = pd.DataFrame(pd.read_csv(file_list[0], sep=',', encoding='latin-1'),columns=CC)\n",
    "for i in range(1,5):\n",
    "    df = pd.DataFrame(pd.read_csv(file_list[i],sep=',' , encoding='latin-1',low_memory=False), columns=CC)\n",
    "    main_dataframe = pd.concat([main_dataframe, df])\n",
    "\n",
    "main_dataframeC=main_dataframe.pivot_table(index=['Area','Year'], columns= ['Element' or 'Item','Unit'], values='Value')\n",
    "main_dataframeC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In the following cell, we are concatanating all the files from the <code>file_list</code>, which will have the same shape thanks to creation of the dataframes with the restriction of the columns. <br>\n",
    "Moreover, this concat function will allow for a single data frame which has all the files one on top of another. Therefore the final result form this loop will be <code>main_dataframe</code> which will be our Normalized Source Data Model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataframe = pd.DataFrame(pd.read_csv(file_list[0], sep=',', encoding='latin-1'),columns=CC)\n",
    "for i in range(1,len(file_list)):\n",
    "    df = pd.DataFrame(pd.read_csv(file_list[i],sep=',' , encoding='latin-1',low_memory=False), columns=CC)\n",
    "    main_dataframe = pd.concat([main_dataframe, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Lastly, to convert the Normalized Source Data Model into the Normalized Integrated Data Model, we are going to use the <code>pivot_table</code> function which allows to <br>\n",
    "adjusts all the variables, previouly called <em>'Elements' & 'Units'</em> into the headers of the columns, and the <em>'Value'</em> column will be the values of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dataframeC=main_dataframe.pivot_table(index=['Area','Year'], columns= ['Element' or 'Item' ,'Unit'], values='Value')\n",
    "main_dataframeC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality assurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we are going to make sure that none of our interesting variables from <em>'Elements'</em> have been left out, thus checking if the extraction & integtration has been completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extraction & integration is COMPLETED and CORRECT\n"
     ]
    }
   ],
   "source": [
    "if len(main_dataframe[\"Element\" or 'Item'].value_counts())==main_dataframeC.shape[1]:\n",
    "    print('Data extraction & integration is COMPLETED and CORRECT')\n",
    "else:\n",
    "    print('Data extraction & integration is UNCOMPLETED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad72b07258a3fa24452fee21e868a537ead700a3a6ac2a1adaf5006160c747dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
