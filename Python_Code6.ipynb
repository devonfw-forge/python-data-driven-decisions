{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c7fa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vperezlo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.22.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vperezlo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.28.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vperezlo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.4.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.22.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.33.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.4.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vperezlo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.22.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vperezlo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vperezlo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#INSTALLS\n",
    "#Install all necessary libraries using pip\n",
    "\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install requests\n",
    "!pip install seaborn\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f20910",
   "metadata": {},
   "source": [
    "## IMPORTS\n",
    "\n",
    "We will need a series of libraries to aid us with the data analysis.\n",
    "\n",
    "The most important ones will be pandas to be able to work with dataframes, numpy as it offers excellent tools to analyze the information, and matplotlib and seaborn which will provide with many options to print the data.\n",
    "\n",
    "But also, we use some other libraries such as os to read the databases from our folder, warnings to be able to raise warnings when needed, and requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9cbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from Testing import "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98938cb",
   "metadata": {},
   "source": [
    "## CONSTANTS AND STRUCTURES\n",
    "\n",
    "In order to keep our code not only readable and clean, but also easy to mantain and modify, we will keep most of our constants and data structures here.\n",
    "\n",
    "Some of them will be strings to specify paths or names of columns, numbers to delimit ranges, or boolean variables to determine the behaviour of some parts of the code. All of these can be changed at will to modify the extension of the analysis and customize the output.\n",
    "\n",
    "Some mutable structures will be kept here as well, since they are intended to behave like constants, like the dictionary to translate some diverse column names to a same given title, or a list with all the special treatment sources that have a predefined preprocessing procedure.\n",
    "\n",
    "Also, we will include some other mutable structures that are intended to have a global scope, like the list of urls, dataframes and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b7f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS AND STRUCTURES TO BE USED\n",
    "\n",
    "read_path = os.getcwd() + '\\Databases' #Path to your databases folder to be read\n",
    "write_path = os.getcwd() + '\\Output' #Path to the folder you want to store the dataframes\n",
    "\n",
    "url_list = [] #List with all the urls for the dataframes successfully read\n",
    "data_list = [] #List containing all the dataframes succesfully read\n",
    "data_dict = {} #Dictionary that correlates the urls with their read databases\n",
    "discarded_urls = [] #List with all the urls whose dataframes could not be read\n",
    "\n",
    "verbose = False #Determines wether full information will be printed or only the most relevant\n",
    "\n",
    "column_country = 'Country' #Name for the column containing the name of the countries\n",
    "column_year = 'Year' #Name for the column containing the years\n",
    "columns_index = [column_country, column_year] #List with all the values for the columns that will be used as indexes\n",
    "columns_rename = dict.fromkeys(['Area', 'Entity', 'Country or Area', 'Name', 'Country Name'], column_country) #Dictionary to rename all the index columns so they have a common name\n",
    "\n",
    "year_min = 1990\n",
    "year_max = 2050\n",
    "year_range = (year_min, year_max)\n",
    "\n",
    "special_source = ['databank', 'faostat', 'kaggle', 'un_data', 'worldbank', 'WID'] #List with all the sources that need special treatment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfd166a",
   "metadata": {},
   "source": [
    "## INDICATORS\n",
    "\n",
    "Since our data comes from many different sources, it is convenient we keep all our indicators in a structure that will allow us to quickly locate them and identify them when reading the files. Since most of them have long, over-describing names, we will use a dictionary so we can later rewrite the title of our columns and make them easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab13a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INDICATORS\n",
    "#Dictionary containing all the indicators to be used, and the aliases for the columns where they will be represented\n",
    "\n",
    "indicators = {\n",
    "    \n",
    "    #databank\n",
    "    'CPIA gender equality rating (1=low to 6=high)': 'Gender Equality',\n",
    "    'Prevalence of undernourishment (% of population)': '% Undernourishment',\n",
    "    \n",
    "    #faostat\n",
    "    'Credit to Agriculture, Forestry and Fishing': 'CreditToAgriFishForest',\n",
    "    '2.a.1 Agriculture value added share of GDP (%)': 'AgriShareGDP',\n",
    "    'Employment by status of employment, total, rural areas': 'EmploymentRural',\n",
    "    'Gross Domestic Product': 'GDP',\n",
    "    'Share of employment in agriculture, forestry and fishing in total employment': '%EmploymentAgriFishForest',\n",
    "    'Agriculture': 'TotalAgri',\n",
    "    \n",
    "    #kaggle\n",
    "    'Gender Inequality': 'Gender Inequality',\n",
    "    \n",
    "    #ourworldindata\n",
    "    'Armed forces personnel (% of total labor force)': '% Soldiers', \n",
    "    'Crude marriage rate (per 1,000 inhabitants)': 'Marriage Rate',\n",
    "    \n",
    "    #theworldbank  \n",
    "    'Birth rate, crude (per 1,000 people)': 'Birth Rate',\n",
    "    'Death rate, crude (per 1,000 people)': 'Death Rate',\n",
    "    'Intentional homicides (per 100,000 people)': 'Homicides',\n",
    "    'Life expectancy at birth, total (years)': 'Life Expectancy',\n",
    "    'Lifetime risk of maternal death (%)': 'Maternal Death Risk',\n",
    "    'Literacy rate, adult total (% of people ages 15 and above)': 'Literacy Rate',\n",
    "    'Mortality rate, infant (per 1,000 live births)': 'Infant Mortality',\n",
    "    'Population growth (annual %)': '% Population Growth',\n",
    "    'Rural population (% of total population)': '% Rural Population',\n",
    "    'Suicide mortality rate (per 100,000 population)': 'Suicide Rate',\n",
    "    \n",
    "    #UN_Data\n",
    "    'Value': 'Gini',\n",
    "    \n",
    "    #WID\n",
    "    #(To Do)\n",
    "    \n",
    "    #WorldInData\n",
    "    'civlib_vdem_owid': 'Civil Liberties',\n",
    "    'Employment-to-population ratio, men (%)': '% Men Employment',\n",
    "    'Employment-to-population ratio, women (%)': '% Women Employment',\n",
    "    'Population (historical estimates)': 'Population',\n",
    "    'freeexpr_vdem_owid': 'Freedom of Expression',\n",
    "    'Indicator:Domestic general government health expenditure (GGHE-D) as percentage of general government expenditure (GGE) (%)': '% Healthcare Investment',\n",
    "    'Industry as % of total employment -- ILO modelled estimates, May 2017': '% Employment Industry',\n",
    "    'UIS: Mean years of schooling of the population age 25+. Female': 'Women Schooling Years',\n",
    "    'UIS: Mean years of schooling of the population age 25+. Male': 'Men Schooling Years',\n",
    "    'Government expenditure on education, total (% of government expenditure)': '% Education Expenditure'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47646f6",
   "metadata": {},
   "source": [
    "## AUXILIARY METHODS\n",
    "\n",
    "Again, as a means to keep the code tidy, readable and easy to modify if needed we have created a series of auxiliary methods separated from the main chunk of code.\n",
    "\n",
    "## RENAME_VALUE_COLUMN\n",
    "The first method will allow us to rename the column that contains the different values of a given indicator. We rename the title of that column to such indicator, either based on the previous name of said column and the one that contains the indicator, either by searching for those.\n",
    "\n",
    "The method will return the modified dataframe or simply modify the given one as a parameter. It will raise an exception if unable to find the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fde6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_value_column(dataframe, column_value = None, column_indicator = None, row_index = 1, inplace = False):\n",
    "    \"\"\"\n",
    "        Method that takes a dataframe and renames the value column with the name of the indicator\n",
    "        \n",
    "        PARAMETERS:\n",
    "            dataframe: dataframe\n",
    "                the dataframe to be modified\n",
    "            column_value: str, default None\n",
    "                the name of the column that contains the values and whose name will be changed. If not specified, it will try to search for it\n",
    "            column_indicator: str, default None\n",
    "                the name of the column that contains the name of the indicator of the dataframe. If not specified, it will try to search for it\n",
    "            inplace: bool, default False\n",
    "                determines if the changes will be made in the same dataframe or returned as a result\n",
    "        \n",
    "        RETURNS:\n",
    "            DataFrame or None\n",
    "                If inplace = False, it will return the modified dataframe. Else, the return will be None and the dataframe\n",
    "        \n",
    "        RAISES:\n",
    "            Exception\n",
    "                If either column_value or column_indicator was not specified, and it was unable to find them itself \n",
    "    \"\"\"\n",
    "    \n",
    "    #If no column name specified, iterate over the list of possible names.\n",
    "    col_values = ['Value']\n",
    "    col_indicators = ['Item', 'Indicator']\n",
    "    \n",
    "    #Try to find\n",
    "    if not column_indicator:\n",
    "        for indicator in col_indicators:\n",
    "            if indicator in dataframe:\n",
    "                column_indicator = indicator\n",
    "    \n",
    "    if not column_value:\n",
    "        for value in col_values:\n",
    "            if value in dataframe:\n",
    "                column_value = value             \n",
    "       \n",
    "    if not column_indicator:\n",
    "        raise Exception('Unable to determine indicator column')\n",
    "    if not column_value:\n",
    "        raise Exception('Unable to determine value column')\n",
    "        \n",
    "    dataframe.rename(columns = {column_value: dataframe.loc[:, column_indicator][1]}, inplace = inplace)\n",
    "    \n",
    "    return dataframe if not inplace else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977074a",
   "metadata": {},
   "source": [
    "## PREPROCESS\n",
    "\n",
    "The second method will take care of the gross preprocessing procedure. Given a dataframe, it will normalize the name of the index columns so they can be later merged together, remove unnecessary columns, shorten the names of the indicators, and melt or apply other changes depending on the specified protocol.\n",
    "\n",
    "It will return the modified and preprocessed dataframe, ready to be merged and treated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a3b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess (dataframe, treatment = '', melt_on_value = None, rename_value_columns = False, inplace = False):\n",
    "    \n",
    "    \"\"\"\n",
    "        Take a dataframe, rearrange its columns or rows, rename them if needed, and return the resulting dataframe\n",
    "        \n",
    "        PARAMETERS:\n",
    "            dataframe: dataframe\n",
    "                the dataframe to be modified\n",
    "            treatment: str, default ''\n",
    "                a flag-like string to indicate that the dataframe must be treated according to a predefined protocol\n",
    "            melt_on_value: str, default None\n",
    "                determines wether the dataframe must be melted on the value specified as the string. If not specified, it will ignore it unless the treatment determines otherwise\n",
    "            rename_value_columns: bool, default False\n",
    "                determines wether the dataframe has a column with values whose header needs to be renamed. If not specified, it will ignore it unless the treatment determines otherwise\n",
    "            inplace: bool, default False\n",
    "                determines if the changes will be made in the same dataframe or returned as a result\n",
    "        \n",
    "        RETURNS:\n",
    "            DataFrame\n",
    "                Return the modified dataframe  \n",
    "    \"\"\"\n",
    "    \n",
    "    match treatment:\n",
    "        \n",
    "        case 'databank':\n",
    "            melt_on_value = dataframe.loc[:, 'Series Name'][1]\n",
    "            dataframe.drop(['Series Name', 'Series Code', 'Country Code'], axis=1, inplace = True)\n",
    "        \n",
    "        case 'faostat':\n",
    "            rename_value_columns = True\n",
    "        \n",
    "        case 'kaggle':            \n",
    "            dataframe.drop(['HDI Rank'], axis=1, inplace = True)\n",
    "            melt_on_value = 'Gender Inequality'\n",
    "        \n",
    "        case 'un_data':\n",
    "            dataframe = dataframe[pd.to_numeric(dataframe[column_year], errors='coerce').notnull()]\n",
    "\n",
    "        case 'worldbank':\n",
    "            melt_on_value = dataframe.loc[:, 'Series Name'][1]\n",
    "            dataframe.drop(['Series Name', 'Series Code', 'Country Code'], axis=1, inplace = True)\n",
    "            \n",
    "    dataframe.rename(columns = columns_rename, inplace = True)\n",
    "    \n",
    "    if rename_value_columns:\n",
    "        rename_value_column(dataframe, inplace = True)\n",
    "    \n",
    "    if melt_on_value:\n",
    "        dataframe = pd.melt(dataframe, id_vars=column_country, var_name = column_year, value_name = melt_on_value)\n",
    "    \n",
    "    for value in dataframe[column_year]: #Normalize year format\n",
    "                if type(value) is not int and len(value) > 4:\n",
    "                    dataframe[column_year].replace({value: str(value[:4])}, inplace = True)\n",
    "    \n",
    "    for column in dataframe.columns: #Drop completely empty columns\n",
    "                if (len(dataframe.loc[:, column].value_counts()) == 1):\n",
    "                    dataframe.drop(column, axis=1, inplace = True) \n",
    "    \n",
    "    #Shorten indicators column name and remove all the other columns except for the index columns\n",
    "    dataframe.rename(columns = indicators, inplace = True)\n",
    "    dataframe.drop(dataframe.columns.difference(columns_index + list(indicators.values())), axis = 1, inplace=True)\n",
    "    \n",
    "    #Remove rows with no country\n",
    "    dataframe.dropna(subset=column_country, inplace=True)\n",
    "    \n",
    "    #Normalize all countries name, removing blank spaces before and after the string\n",
    "    dataframe[column_country] = dataframe[column_country].str.strip()\n",
    "    dataframe.replace(['..'], '', inplace=True)\n",
    "    \n",
    "    #Narrow the range of the data to the years selected\n",
    "    dataframe[column_year]= dataframe[column_year].astype(int)\n",
    "    dataframe.drop(dataframe[dataframe[column_year] < year_min].index, inplace=True)\n",
    "    \n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a29946",
   "metadata": {},
   "source": [
    "## MAIN CODE\n",
    "\n",
    "The following cells of code will contain the main part of the code, and will be divided according to the different stages of the data processing they take care of.\n",
    "\n",
    "## READING\n",
    "\n",
    "The first step will explore the directory specified in the str read_path, check what files are .csv, and try to read and preprocess them. Those succesfully read and processed will be stored in a dictionary with their url as a key. Both of them, dataframes and url, will also be stored in two lists.\n",
    "\n",
    "For those .csv that cannot be read or processed, we will store their url in a discarded list, and raise a warning should there be any faulty url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbd613d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vperezlo\\AppData\\Local\\Temp\\ipykernel_22088\\4273712642.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.rename(columns = columns_rename, inplace = True)\n",
      "C:\\Users\\vperezlo\\AppData\\Local\\Temp\\ipykernel_22088\\4273712642.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.rename(columns = indicators, inplace = True)\n",
      "C:\\Users\\vperezlo\\AppData\\Local\\Temp\\ipykernel_22088\\4273712642.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.drop(dataframe.columns.difference(columns_index + list(indicators.values())), axis = 1, inplace=True)\n",
      "C:\\Users\\vperezlo\\AppData\\Local\\Temp\\ipykernel_22088\\4273712642.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.dropna(subset=column_country, inplace=True)\n",
      "C:\\Users\\vperezlo\\AppData\\Local\\Temp\\ipykernel_22088\\4273712642.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[column_country] = dataframe[column_country].str.strip()\n",
      "C:\\Users\\vperezlo\\AppData\\Local\\Temp\\ipykernel_22088\\4273712642.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.replace(['..'], '', inplace=True)\n",
      "C:\\Users\\vperezlo\\AppData\\Local\\Temp\\ipykernel_22088\\4273712642.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[column_year]= dataframe[column_year].astype(int)\n",
      "C:\\Users\\vperezlo\\AppData\\Local\\Temp\\ipykernel_22088\\4273712642.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe.drop(dataframe[dataframe[column_year] < year_min].index, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#||||||||||START OF MAIN CODE|||||||||||||\n",
    "\n",
    "#Explore all the files from the specified directory in read_path\n",
    "#If the file is a .csv, try to read it, preprocess it and append it to the list of dataframes\n",
    "#If any error is raised during the process, it appends the url to the list of discarded files and shows a warning at the end\n",
    "\n",
    "for element in listdir(read_path):\n",
    "        url = join(read_path, element)\n",
    "        if isfile(url) and url.endswith('.csv'):\n",
    "            url_list.append(url)\n",
    "            if 'WID' in url:\n",
    "                continue\n",
    "            try:\n",
    "                dataframe = pd.read_csv(url)\n",
    "            except:\n",
    "                print('Unable to read dataframe: ' + url)\n",
    "                discarded_urls.append(url)\n",
    "            else:\n",
    "                special = None\n",
    "                for source in special_source:\n",
    "                    if source in url.lower():\n",
    "                        special = source\n",
    "                        break\n",
    "                \n",
    "                try:\n",
    "                    dataframe = preprocess(dataframe, treatment = special)\n",
    "                except:\n",
    "                    print('Unexpected error when preprocessing the dataframe: ' + url)\n",
    "                    discarded_url.append(url)\n",
    "                else:\n",
    "                    url_list.append(url)\n",
    "                    data_list.append(dataframe)\n",
    "                    data_dict[url] = dataframe\n",
    "\n",
    "if len(discarded_urls) > 0:\n",
    "        warn = 'Unable to read the following files:'\n",
    "        for url in discarded_urls:\n",
    "            warn += '\\n' + url\n",
    "        warnings.warn(warn)                    \n",
    "                    \n",
    "if (verbose):\n",
    "    for data in data_list:\n",
    "        print(data)\n",
    "        print('\\n' + '----------------------------------------------------------' + '\\n')\n",
    "else:\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a9c56f",
   "metadata": {},
   "source": [
    "# Merge\n",
    "\n",
    "This is the process of integration of all the databases. In first place, all the column of Country and Year must be casted to a string in order to avoid errors. After this the merge function is performed with the 'outer' parameter to avoid losing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00f71f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vperezlo\\AppData\\Local\\Temp\\ipykernel_22088\\2791216442.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column_year]= data[column_year].astype(str)\n",
      "C:\\Users\\vperezlo\\AppData\\Local\\Temp\\ipykernel_22088\\2791216442.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column_country]= data[column_country].astype(str)\n"
     ]
    }
   ],
   "source": [
    "final_df = data_list[0]\n",
    "\n",
    "final_df[column_year]= final_df[column_year].astype(str)\n",
    "final_df[column_country]= final_df[column_country].astype(str)\n",
    "\n",
    "#Merge all the different databases into one single dataframe with the format: columns_index + indicators\n",
    "for data in data_list[1:]:\n",
    "    data[column_year]= data[column_year].astype(str)\n",
    "    data[column_country]= data[column_country].astype(str)\n",
    "    final_df = pd.merge(final_df, data, on = columns_index, how = \"outer\")\n",
    "\n",
    "#final_df contains the whole merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d4d44f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_country = {} #Ad-hoc dictionary to count the number of entries for each country\n",
    "dict_df_countries = {} #Dictionary that relates each country to its dataframe\n",
    "VALUE = 1\n",
    "THRESHOLD = 15 #Minimum number of entries a country needs to have to be included into our research\n",
    "\n",
    "\n",
    "#Counts all the entries for each country and stores into the dictionary with countries as keys and the count as its associated value    \n",
    "for country in final_df[column_country]:\n",
    "    if country not in dict_country:\n",
    "        dict_country[country] = VALUE\n",
    "    else:\n",
    "        dict_country[country] += VALUE\n",
    "\n",
    "#Removes all the countries that do no meet the minimun entries requirement        \n",
    "dict_country = {country:num for country, num in dict_country.items() if num >= THRESHOLD}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27206669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smanoles\\AppData\\Local\\Temp\\ipykernel_16468\\2497589818.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dict_df_countries['Spain'][dict_df_countries['Spain'].columns[2:]] = dict_df_countries['Spain'][dict_df_countries['Spain'].columns[2:]].apply(pd.to_numeric, errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "for country in dict_country.keys():\n",
    "    df = final_df.loc[final_df[column_country] == country]\n",
    "    dict_df_countries[country] = df\n",
    "    \n",
    "\n",
    "#dict_df_countries['Spain'].columns\n",
    "dict_df_countries['Spain'][dict_df_countries['Spain'].columns[2:]] = dict_df_countries['Spain'][dict_df_countries['Spain'].columns[2:]].apply(pd.to_numeric, errors='ignore')\n",
    "dict_df_countries['Spain'].corr()\n",
    "for element in dict_df_countries['Spain']['% Undernourishment']:\n",
    "    print(type(element))\n",
    "#dict_df_countries['Spain']['% Undernourishment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in range(-10000, 2050):\n",
    "    df = final_df.loc[final_df[column_country] == country]\n",
    "    dict_df_countries[country] = df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "6044c39f3fa8d69f78786198aef61ed0dc3fdd7ddd5a88c111ee27e3b3325eb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
